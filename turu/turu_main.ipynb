{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "32cdc549",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\irgit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "\n",
    "import pickle\n",
    "\n",
    "import joblib\n",
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, f1_score, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "77ba8f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка тувинского датасета\n",
    "shyn = pd.read_csv(r'e:\\WORK\\Tu_RU\\datasets\\tu\\tuva_text.csv')\n",
    "gov = pd.read_csv(r'e:\\WORK\\Tu_RU\\datasets\\tu\\govtuva.csv')\n",
    "\n",
    "shyn.columns = ['id','text']\n",
    "gov.columns = ['id','text']\n",
    "\n",
    "data = pd.concat([shyn,gov], ignore_index=True)\n",
    "del data['id']\n",
    "data.dropna\n",
    "df_tu = data\n",
    "\n",
    "df_tu['type'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "813559ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка русского датасета\n",
    "folder = r'e:\\WORK\\Tu_RU\\datasets\\ru\\news\\KP\\texts'\n",
    "text = []\n",
    "file_list = glob.glob(folder + \"/*.txt\")\n",
    "for x in file_list:\n",
    "    with open(x, encoding=\"utf8\") as f:        \n",
    "        lines = f.readlines()\n",
    "        text.append(' '.join(lines))\n",
    "df_ru = pd.DataFrame(text)\n",
    "df_ru['type'] = 0\n",
    "df_ru.columns = ['text','type']\n",
    "df_ru = df_ru[0:9000]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "087137c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_tu[0:500],df_ru[0:500]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "a5454401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция отчистки текста\n",
    "def text_preroccesor(text):\n",
    "    text = str(text).lower()\n",
    "    tokens = [x for x in text.split() if x not in russian_stopwords and x.isalpha()]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "ff928f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ошищаем датафрейм от мусора text_preroccesor(text)\n",
    "df['text'] = df['text'].apply(lambda x: text_preroccesor(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "7879ee5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбиваем выборку на тренировачную и тестовую выборку\n",
    "df_train, df_test = train_test_split(df, test_size=0.20, stratify=df.type)\n",
    "\n",
    "# Делаем векторизацию\n",
    "vec = CountVectorizer(\n",
    "    ngram_range=(1, 3), \n",
    "    stop_words=None,\n",
    ")\n",
    "\n",
    "# Применяем метод трансформеров\n",
    "X_train = vec.fit_transform(df_train.text)\n",
    "X_test = vec.transform(df_test.text)\n",
    "\n",
    "y_train = df_train.type\n",
    "y_test = df_test.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "73909063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       100\n",
      "           1       1.00      1.00      1.00       100\n",
      "\n",
      "    accuracy                           1.00       200\n",
      "   macro avg       1.00      1.00      1.00       200\n",
      "weighted avg       1.00      1.00      1.00       200\n",
      "\n",
      "Test score: 99.98 %\n",
      "Плотности слова в векторе 112508\n"
     ]
    }
   ],
   "source": [
    "# Обучаем модель clf на базе MultinomialNB \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, preds))\n",
    "print(\"Test score: {0:.2f} %\".format(100 * score))\n",
    "\n",
    "# Инфа по плотности слова в векторе (с маленькой буквы)\n",
    "print(f'Плотности слова в векторе', vec.vocabulary_.get(u'кызыл'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "081e09dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == \"__main__\":\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>чылдың июль хүндүлүг солуннуң чагыдып ооң идег...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>алефтина суурда кожуун чергелиг культура килди...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>россия биле тываның демнежилгезиниң чылынга чу...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>тыва республиканың дээди хуралында тыва респуб...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>съемки программы первого канала завершились ал...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>чоокта чаа республиканың тыва спортчулары ново...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>псковский государственный университет совместн...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>псковские фехтовальщики поучаствовали турнире ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>марттың сураглыг ыраажы чаңгыс намчылактың төр...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>тыва парлалганың хүндүлүг сеткиливис ханызында...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  type  predict\n",
       "288  чылдың июль хүндүлүг солуннуң чагыдып ооң идег...     1        1\n",
       "175  алефтина суурда кожуун чергелиг культура килди...     1        1\n",
       "240  россия биле тываның демнежилгезиниң чылынга чу...     1        1\n",
       "78   тыва республиканың дээди хуралында тыва респуб...     1        1\n",
       "703  съемки программы первого канала завершились ал...     0        0\n",
       "201  чоокта чаа республиканың тыва спортчулары ново...     1        1\n",
       "689  псковский государственный университет совместн...     0        0\n",
       "566  псковские фехтовальщики поучаствовали турнире ...     0        0\n",
       "475  марттың сураглыг ыраажы чаңгыс намчылактың төр...     1        1\n",
       "162  тыва парлалганың хүндүлүг сеткиливис ханызында...     1        1"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Тесттируем на Датафрейме\n",
    "def get_predict(text):\n",
    "    data = [text]   \n",
    "    x_new = vec.transform(data)\n",
    "    preds = clf.predict(x_new)\n",
    "    return preds[0]\n",
    "\n",
    "df_test = df_train[40:50]\n",
    "df_test['predict'] = df_test['text'].apply(lambda x: get_predict(x))\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "17177a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Текст на тувинском языке\n"
     ]
    }
   ],
   "source": [
    "# Тестируем на тексте\n",
    "text_in = \"\"\"\n",
    "Эрткен чылдың түңнелдери-биле алырга, Тывада туберкулезтан аарыыр чорук эвежээни демдеглеттинген. Фтизиатрлар ниитилелиниң хуралында, республиканың фтизиатрия албанының дыңнаткан сан-чурагайлары-биле алырга, 2022 чылда 100 муң кижиге онааштыр 113,5 кижи аарып, 2021 чылдан 8 хуу эвээжээни айыттынган. Бир дугаар илереттинген аарыг кижилер саны 11,6 хуу кызырылган ( 45,3 хуудан 33,7 хууже).\n",
    "Туберкулезтан аарыыр болгаш өлүп-хораар чорукту элээн эвээжедир дизе, шупту субъектилерниң талазындан кады ажылдажылганы база ведомстволар аразында удур-дедир харылзаалыг ажылды күштелдирер херек деп, специалистер санаан. Ол ышкаш чон-биле санитарлыг-чырыдыышкын ажылын идепкейжидери чугула деп, эмчилер демдеглээн.\n",
    "Халдавырлыг аарыглар санын эвээжедири база дезинфекцияны чорудары чугула черни ойнаарын демдеглээн. Регион чазааның деткимчези-биле эрткен чылын тус черниң фтизатрия албаны көжүп чоруур чаа ийи дезинфекция камераларын садып алганы, эпидемияның үнүп кээп болур черлерин каш катап эвээжеткен. Дезкамераларның бирээзин доктаамал ажыглаар кылдыр Барыын-Хемчикче чоруткан. Оон Бай-Тайга, Чөөн-Хемчик, Өвүр база Мөңгүн-Тайга кожууннарже үнүүшкүннерже үнер. Дезинфекция дериг-херекселдерин немей тургусканы ажылдың шынарынга салдарны чедирер деп, специалистер санаан.\n",
    "Россияның Президентизи Владимир Путинниң регионга тускайжыттынган чаа эмчи объектизин – Тывага туберкулезка удур амгы үениң диспансер тудуун деткээни-биле, бо чоокку чылдарда ол тудуг туттунарын сагындыраал. Амгы үеде объектиниң төлевилел-смета документациязын белеткеп турар. Тываның Баштыңы Владислав Ховалыг туберкулезка удур демисел мурнады боттандырар ажылдарның бирээзи болганда, диспансер тудуунга хамааржыр шупту айтырыгларны бодунуң контролюнда тудуп турарын чугаалаан.\n",
    "Тываның Баштыңы бодунуң Айыткалында сонуургалдыг ведомстволар-биле кады туберкулезка удур демисежир үр хуусаалыг регион программазын ажылдып кылгаш, “орук картазының” хемчеглерин база сорулгалыг көргүзүглерин чада аайы-биле чедип алыр даалганы республиканың Кадык камгалал яамызынга берген турган.\n",
    "\"\"\"\n",
    "x_new = vec.transform([text_in])\n",
    "preds = clf.predict(x_new)\n",
    "\n",
    "if preds[0] == 1:\n",
    "    print('Текст на тувинском языке')\n",
    "else:\n",
    "    print('Текст на русском языке')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "0d7cc7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранить модель\n",
    "model_file = r'e:\\WORK\\Tu_RU\\datasets\\turu_model.pkl'\n",
    "\n",
    "with open(model_file, 'wb') as file: \n",
    "    #pickle.dump(clf, file)\n",
    "    pickle.dump((vec, clf), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d4a405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f236ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41733321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92962623",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
